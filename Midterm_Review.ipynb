{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visualize all variables\n",
    "\n",
    "sns.pairplot(admissions, hue='admit', size=3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lm = linear_model.LinearRegression() \n",
    "\n",
    "define y\n",
    "target = 'psoda'\n",
    "y = fast_food[target]\n",
    "print type(y)\n",
    "\n",
    "define x\n",
    "X = fast_food[['prpblck', 'income']]\n",
    "print type(X)\n",
    "\n",
    "run regression \n",
    "model = lm.fit(X, y)\n",
    "\n",
    "# Predict your y, call them predictions, print the shape of predictions\n",
    "# Print the shape of predictions\n",
    "predictions = lm.predict(X)\n",
    "predictions.shape\n",
    "\n",
    "compare means\n",
    "print fast_food['psoda'].mean()\n",
    "print predictions.mean()\n",
    "\n",
    "finding r-squared\n",
    "score_r2 = model.score(X, y)\n",
    "score_r2\n",
    "\n",
    "Estimates\n",
    "model.coef_\n",
    "lm.intercept_\n",
    "\n",
    "\n",
    "\n",
    "using stats models:\n",
    "import statsmodels.formula.api as smf\n",
    "lm = smf.ols(formula='psoda ~ prpblck + income', data=fast_food).fit()\n",
    "lm.params\n",
    "lm.summary()\n",
    "\n",
    "visualization\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.regplot(fast_food['prpblck'], fast_food['psoda'], data=fast_food)\n",
    "plt.show()\n",
    "\n",
    "correlation matrix\n",
    "cor_var = ['prppov', 'lincome']\n",
    "fast_food[cor_var].corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing your x Variables:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "Xn = ss.fit_transform(X)\n",
    "\n",
    "Split Train and Test:\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xn, y, test_size=0.3, random_state=10)\n",
    "print X_train.shape, X_test.shape\n",
    "print \"\\n======\\n\"\n",
    "print y_train.shape, y_test.shape\n",
    "\n",
    "Linear Regression with sklearn:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "Compare test and train:\n",
    "def rsquare_meansquare_error(train_y, test_y, train_X, test_X, test, best_model):\n",
    "    \"\"\" first we need to predict on the test and train data\"\"\"\n",
    "    y_train_pred = best_model.predict(train_X)\n",
    "    y_test_pred = best_model.predict(test_X)\n",
    "    \n",
    "\"\"\" We call the MSE in the following lines\"\"\"\n",
    "    print ('MSE ' + test + ' train data: %.2f, test data: %.2f' % (\n",
    "        mean_squared_error(train_y, y_train_pred),\n",
    "        mean_squared_error(test_y, y_test_pred)))\n",
    "        \n",
    "\"\"\" We call the R^2 in the following lines\"\"\"\n",
    "    print('R^2 ' + test + ' train data: %.2f, test data: %.2f' % (\n",
    "        r2_score(train_y, y_train_pred),\n",
    "        r2_score(test_y, y_test_pred)))\n",
    "        \n",
    "Basic OLS prediction:\n",
    "rsquare_meansquare_error(y_train, y_test, X_train, X_test, \"OLS\", lr)\n",
    "\n",
    "Ridge Regression:\n",
    "\n",
    "    Find Alpha:\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV\n",
    "ridge_alphas = np.logspace(0, 5, 100)\n",
    "optimal_ridge = RidgeCV(alphas=ridge_alphas, cv=10)\n",
    "optimal_ridge.fit(X_train, y_train)\n",
    "print (optimal_ridge.alpha_)\n",
    "\n",
    "Calculate Ridge and Fit Train/Test:\n",
    "ridge = Ridge(alpha=optimal_ridge.alpha_)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "Evaluate Ridge:\n",
    "rsquare_meansquare_error(y_train, y_test, X_train, X_test, \"Ridge\", ridge)\n",
    "\n",
    "Compare the r^2 and MSE of train and test to see how the estimation did\n",
    "\n",
    "Lasso:\n",
    "    Optimal Alpha:\n",
    " optimal_lasso = LassoCV(n_alphas=300, cv=10, verbose=1)\n",
    "optimal_lasso.fit(X_train, y_train)\n",
    "print optimal_lasso.alpha_\n",
    "\n",
    "Implement, Fit, and Evaluate Regression1:\n",
    "\n",
    "lasso = Lasso(alpha=optimal_lasso.alpha_)\n",
    "lasso.fit(X_train, y_train)\n",
    "rsquare_meansquare_error(y_train, y_test, X_train, X_test, \"Lasso\", lasso)\n",
    "\n",
    "Elastic Net Regression:\n",
    "    Optimal Alpha:\n",
    "l1_ratios = np.linspace(0.01, 1.0, 50)\n",
    "optimal_enet = ElasticNetCV(l1_ratio=l1_ratios, n_alphas=300, cv=5, verbose=1)\n",
    "optimal_enet.fit(X_train, y_train)\n",
    "print optimal_enet.alpha_\n",
    "print optimal_enet.l1_ratio_\n",
    "\n",
    "Create, Fit, and Evaluate:\n",
    "enet = ElasticNet(alpha=optimal_enet.alpha_, l1_ratio=optimal_enet.l1_ratio_)\n",
    "enet.fit(X_train, y_train)\n",
    "rsquare_meansquare_error(y_train, y_test, X_train, X_test, \"Elastic Net\", enet)\n",
    "\n",
    "\n",
    "Regression Tree: \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "GridSearch:\n",
    "params = {\"max_depth\": [3,5,10,20],\n",
    "          \"max_features\": [None, \"auto\"],\n",
    "          \"min_samples_leaf\": [1, 3, 5, 7, 10],\n",
    "          \"min_samples_split\": [2, 5, 7],\n",
    "           \"criterion\" : ['mse']\n",
    "         }\n",
    "Cross Validate:\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "dtr_gs = GridSearchCV(dtr, params, n_jobs=-1, cv=5, verbose=1)\n",
    "\n",
    "fit Tree:\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "dtr_gs = GridSearchCV(dtr, params, n_jobs=-1, cv=5, verbose=1)\n",
    "\n",
    "Best Estimate:\n",
    "''' dtr_best = is the regression tree regressor with best parameters/estimators'''\n",
    "dtr_best = dtr_gs.best_estimator_ \n",
    "\n",
    "print \"best estimator\", dtr_best\n",
    "print \"\\n==========\\n\"\n",
    "print \"best parameters\",  dtr_gs.best_params_\n",
    "print \"\\n==========\\n\"\n",
    "print \"best score\", dtr_gs.best_score_\n",
    "\n",
    "\n",
    "Find X's that best explain y:\n",
    "def feature_importance(X, best_model):\n",
    "    feature_importance = pd.DataFrame({'feature':X.columns, 'importance':best_model.feature_importances_})\n",
    "    feature_importance.sort_values('importance', ascending=False, inplace=True)\n",
    "    return feature_importance  \n",
    "feature_importance(X, dtr_best)\n",
    "\n",
    "Predict and Evaluate:\n",
    "y_pred_dtr= dtr_best.predict(X_test)\n",
    "y_pred_dtr\n",
    "\n",
    "rsquare_meansquare_error(y_train, y_test, X_train, X_test, \"Regression tree\", dtr_best)\n",
    "\n",
    "Visualize the Tree:\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import pydot\n",
    "\n",
    "dot_data = StringIO()\n",
    "''' dtr_best was previously defined'''\n",
    "\n",
    "export_graphviz(dtr_best, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,\n",
    "                feature_names=X.columns)  \n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())  \n",
    "\n",
    "\n",
    "\n",
    "Random Forest:\n",
    " Grid Search:\n",
    " from sklearn.ensemble import RandomForestRegressor\n",
    "forest = RandomForestRegressor( )\n",
    "\n",
    "params = {'max_depth':[3,4,5],  \n",
    "          'max_leaf_nodes':[5,6,7], \n",
    "          'min_samples_split':[3,4],\n",
    "          'n_estimators': [100]\n",
    "         }\n",
    "\n",
    "estimator_rfr = GridSearchCV(forest, params, n_jobs=-1,  cv=5,verbose=1)\n",
    "\n",
    "Fit and Estimate Forest:\n",
    "estimator_rfr.fit(X_train, y_train)\n",
    "\n",
    "''' rfr_best = is the random forest regression tree regressor with best parameters/estimators'''\n",
    "rfr_best = estimator_rfr.best_estimator_\n",
    "print \"best estimator\", rfr_best\n",
    "print \"\\n==========\\n\"\n",
    "print \"best parameters\", estimator_rfr.best_params_\n",
    "print \"\\n==========\\n\"\n",
    "print \"best score\", estimator_rfr.best_score_\n",
    "\n",
    "See Most Important Variables:\n",
    "feature_importance(X, rfr_best)\n",
    "\n",
    "Predict:\n",
    "y_pred_rfdtr= rfr_best.predict(X_test)\n",
    "y_pred_rfdtr\n",
    "\n",
    "Evaluate:\n",
    "rsquare_meansquare_error(y_train, y_test, X_train, X_test, \"Random Forest Regression tree\", rfr_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
